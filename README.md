# ğŸ¯ NB-Whisper Finetuning Starter Kit

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red.svg)](https://pytorch.org/)
[![Windows](https://img.shields.io/badge/Platform-Windows%2010%2F11-blue.svg)](https://www.microsoft.com/windows)

> **Professional toolkit to adapt NbAiLab/nb-whisper-large to your own Norwegian data**

A comprehensive, Windows-friendly pipeline for fine-tuning Norwegian Whisper models with minimal setup and maximum reproducibility.

## ğŸ“‹ Table of Contents

- [âœ¨ Features](#-features)
- [ğŸ¯ Target Audience](#-target-audience)
- [ğŸ“Š Project Comparison](#-project-comparison)
- [âš™ï¸ System Requirements](#ï¸-system-requirements)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“– Detailed Usage](#-detailed-usage)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ”§ Troubleshooting](#-troubleshooting)
- [ğŸ“„ License](#-license)

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ”„ **End-to-End Pipeline** | Complete workflow: dataset preparation â†’ fine-tuning â†’ evaluation â†’ inference |
| ğŸ” **Model Analysis** | Comprehensive model inspection and step-wise token generation tracing |
| ğŸ’» **Windows Native** | PowerShell commands ready out of the box |
| ğŸ“Š **TensorBoard Integration** | Real-time training monitoring with detailed logs |
| ğŸ¯ **Minimal Dependencies** | Clean, focused implementation without bloat |
| âš¡ **GPU & CPU Support** | Flexible deployment options for different hardware |

**Base Model**: [`NbAiLab/nb-whisper-large`](https://huggingface.co/NbAiLab/nb-whisper-large) (Apache-2.0)

## ğŸ¯ Target Audience

- **ğŸ”§ Windows Developers** seeking quick NB-Whisper fine-tuning on custom data
- **ğŸ‘¨â€ğŸ’¼ ML Practitioners** needing minimal, reproducible pipelines without heavy infrastructure
- **ğŸ“ Researchers** wanting practical PyTorch implementation over complex research setups

## ğŸ“Š Project Comparison

| Aspect | Official nb-whisper | This Starter Kit |
|--------|-------------------|------------------|
| **Focus** | Research-oriented Flax/TPU training | Practical PyTorch Windows starter |
| **Dependencies** | Complex research stack | Minimal, focused dependencies |
| **Platform** | Multi-platform research | Windows-optimized development |
| **Use Case** | Experiments & research | Production-ready fine-tuning |

ğŸ“š **Official Repository**: [NbAiLab/nb-whisper](https://github.com/NbAiLab/nb-whisper)

## âš™ï¸ System Requirements

| Component | Requirement | Notes |
|-----------|-------------|-------|
| **OS** | Windows 10/11 | Tested on both versions |
| **Python** | 3.10+ | Tested with 3.11 |
| **Hardware** | CPU (smoke tests) / GPU (CUDA 12.4) | GPU recommended for production |
| **Memory** | 8GB+ RAM | 16GB+ recommended for GPU training |

## ğŸš€ Quick Start

### Step 1: Environment Setup

<details>
<summary>ğŸ”§ <strong>Initial Setup</strong></summary>

```powershell
# Create virtual environment
py -3 -m venv .venv

# Install base requirements
./.venv/Scripts/pip install -r requirements.txt
```

**Choose PyTorch variant:**

```powershell
# ğŸ’» CPU Version (for testing)
./.venv/Scripts/pip install --index-url https://download.pytorch.org/whl/cpu torch torchaudio

# ğŸš€ GPU Version (recommended for training)
./.venv/Scripts/pip install --index-url https://download.pytorch.org/whl/cu124 torch torchaudio
```
</details>

### Step 2: Verify Installation

```powershell
# Test base model inference
./.venv/Scripts/python scripts/asr_infer.py data/audio/king.mp3 --model_path NbAiLab/nb-whisper-large --device cpu --num_beams 5
```

### Step 3: Dataset Preparation

```powershell
# Auto-generate dataset from audio files
./.venv/Scripts/python scripts/prepare_dataset.py data/audio \
  --out_csv data/train.csv \
  --out_json data/train.json \
  --model NbAiLab/nb-whisper-large \
  --device cpu \
  --num_beams 5 \
  --val_fraction 0.1 \
  --out_csv_val data/val.csv \
  --out_json_val data/val.json
```

> ğŸ“ **Important**: Edit `data/train.csv` to ensure transcript accuracy. Format: `audio,text`. Prefer clips â‰¤ 30s.

### Step 4: Training

<details>
<summary>ğŸ§ª <strong>Quick Demo Run (CPU)</strong></summary>

```powershell
./.venv/Scripts/python train/finetune.py \
  --model_id NbAiLab/nb-whisper-large \
  --dataset data/train.csv \
  --max_steps 5 \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 4 \
  --seed 42
```
</details>

<details>
<summary>ğŸš€ <strong>Production Training (GPU)</strong></summary>

```powershell
./.venv/Scripts/python train/finetune.py \
  --model_id NbAiLab/nb-whisper-large \
  --dataset data/train.csv \
  --dataset_eval data/val.csv \
  --num_train_epochs 1 \
  --per_device_train_batch_size 4 \
  --gradient_accumulation_steps 4 \
  --fp16 \
  --seed 42
```
</details>

**ğŸ“‚ Outputs**: Model saved to `outputs/whisper-finetuned/`, logs in `runs/`

### Step 5: Monitoring & Evaluation

<details>
<summary>ğŸ“Š <strong>TensorBoard Setup</strong></summary>

```powershell
# Install and launch TensorBoard
./.venv/Scripts/python -m pip install tensorboard
./.venv/Scripts/tensorboard --logdir runs --host 127.0.0.1 --port 6006
```
Open: [http://127.0.0.1:6006](http://127.0.0.1:6006)
</details>

<details>
<summary>ğŸ“ˆ <strong>Model Evaluation</strong></summary>

```powershell
# Compare base vs fine-tuned models
./.venv/Scripts/python scripts/asr_infer.py data/audio/king.mp3 --model_path NbAiLab/nb-whisper-large --device cpu --num_beams 5
./.venv/Scripts/python scripts/asr_infer_finetuned.py data/audio/king.mp3 --model_path outputs/whisper-finetuned --device cpu --num_beams 5

# Evaluate WER on validation set
./.venv/Scripts/python scripts/eval_wer.py data/val.csv --model_path outputs/whisper-finetuned --device cpu --num_beams 5
```
</details>

## ğŸ“– Detailed Usage

### ğŸ” Model Analysis Tools

<details>
<summary><strong>Model Inspection</strong></summary>

```powershell
# Generate model structure summary
./.venv/Scripts/python scripts/inspect_model.py \
  --model_path NbAiLab/nb-whisper-large \
  --out analysis_model_summary.txt

# Trace token generation process
./.venv/Scripts/python scripts/trace_generate.py data/audio/king.mp3 \
  --model_path NbAiLab/nb-whisper-large \
  --max_new_tokens 64 \
  --num_beams 5 \
  --out analysis_trace.txt
```
</details>

### âš ï¸ Current Limitations

| Limitation | Description | Workaround |
|------------|-------------|------------|
| **Training Method** | Full-model fine-tuning only (no LoRA/PEFT) | Use `--max_steps` for quick experiments |
| **Audio Processing** | No speaker diarization or VAD | Preprocess audio externally if needed |
| **Performance** | Auto-transcription slow on CPU | Use GPU or prepare transcripts manually |
| **Data Augmentation** | Basic augmentations only | Extend `finetune.py` for advanced techniques |

## ğŸ“ Project Structure

```
nb-whisper-finetune/
â”œâ”€â”€ ğŸ“ scripts/              # Core functionality
â”‚   â”œâ”€â”€ ğŸ” asr_infer.py           # Base model inference
â”‚   â”œâ”€â”€ ğŸ¯ asr_infer_finetuned.py # Fine-tuned model inference  
â”‚   â”œâ”€â”€ ğŸ“Š prepare_dataset.py     # Dataset preparation & auto-transcription
â”‚   â”œâ”€â”€ ğŸ” inspect_model.py       # Model structure analysis
â”‚   â”œâ”€â”€ ğŸ“ˆ trace_generate.py      # Token generation tracing
â”‚   â””â”€â”€ ğŸ“Š eval_wer.py           # WER evaluation
â”œâ”€â”€ ğŸ“ train/
â”‚   â””â”€â”€ ğŸš€ finetune.py            # Full-model fine-tuning pipeline
â”œâ”€â”€ ğŸ“ data/                 # Your datasets (gitignored)
â”œâ”€â”€ ğŸ“ outputs/              # Fine-tuned models (gitignored)  
â”œâ”€â”€ ğŸ“ runs/                 # TensorBoard logs (gitignored)
â”œâ”€â”€ ğŸ“„ requirements.txt      # Python dependencies
â””â”€â”€ ğŸ“– README.md            # This guide
```

## ğŸ”§ Troubleshooting

<details>
<summary>ğŸ’» <strong>Command Line Issues</strong></summary>

| Issue | Solution |
|-------|----------|
| Commands not working | Run in **PowerShell** (`PS ...`), not Python REPL (`>>>`) |
| Virtual environment not activating | Ensure you're using `./.venv/Scripts/` prefix |
| Permission denied | Run PowerShell as Administrator if needed |

</details>

<details>
<summary>ğŸµ <strong>Audio & Data Issues</strong></summary>

| Issue | Solution |
|-------|----------|
| Training unstable with long audio | Split clips to â‰¤ 30 seconds |
| Poor transcription quality | Manually review and edit `data/train.csv` |
| Out of memory errors | Reduce batch size or use gradient accumulation |

</details>

<details>
<summary>âš¡ <strong>Performance Issues</strong></summary>

| Issue | Solution |
|-------|----------|
| CPU training too slow | Use `--max_steps 5` for testing, GPU for production |
| TorchCodec warnings | `pip uninstall -y torchcodec` (we use torchaudio) |
| GPU out of memory | Reduce batch size or enable `--fp16` |

</details>

<details>
<summary>ğŸ› ï¸ <strong>System Issues</strong></summary>

| Issue | Solution |
|-------|----------|
| Windows symlinks warning | Harmless; optionally enable Developer Mode |
| HuggingFace cache issues | Clear cache: `rm -rf ~/.cache/huggingface/` |
| CUDA version mismatch | Reinstall PyTorch with correct CUDA version |

</details>

## ğŸ“„ License

### Code License
This project is licensed under **Apache-2.0** - see [LICENSE](LICENSE) file for details.

### Model License  
**Base Model**: [`NbAiLab/nb-whisper-large`](https://huggingface.co/NbAiLab/nb-whisper-large) (Apache-2.0)

### Attribution
- **Maintainer**: [axngwb](https://github.com/axngwb)
- **Base Model**: Norwegian AI Lab (NbAiLab)